{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">  Chat Bot using NLP </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "Full Details: https://research.fb.com/downloads/babi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our data is containig the tuple of 3 lists first one contaning the story , second one with the question related to that story and third with the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the test and train data set for the vocab\n",
    "all_data = test_data + train_data\n",
    "\n",
    "#print(all_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addiding story, question and anwer words to the vocab\n",
    "for story, question , answer in all_data:\n",
    "   \n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 1,\n",
       " 'kitchen': 2,\n",
       " 'john': 3,\n",
       " 'bedroom': 4,\n",
       " 'grabbed': 5,\n",
       " 'picked': 6,\n",
       " 'travelled': 7,\n",
       " 'up': 8,\n",
       " 'office': 9,\n",
       " 'is': 10,\n",
       " 'no': 11,\n",
       " 'yes': 12,\n",
       " 'went': 13,\n",
       " 'took': 14,\n",
       " 'bathroom': 15,\n",
       " '?': 16,\n",
       " 'mary': 17,\n",
       " 'back': 18,\n",
       " 'discarded': 19,\n",
       " 'daniel': 20,\n",
       " 'milk': 21,\n",
       " 'apple': 22,\n",
       " 'in': 23,\n",
       " 'journeyed': 24,\n",
       " 'moved': 25,\n",
       " 'sandra': 26,\n",
       " 'put': 27,\n",
       " 'left': 28,\n",
       " 'there': 29,\n",
       " 'garden': 30,\n",
       " 'got': 31,\n",
       " 'dropped': 32,\n",
       " 'to': 33,\n",
       " 'football': 34,\n",
       " 'hallway': 35,\n",
       " '.': 36,\n",
       " 'the': 37}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    \n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 37,  4, 36],\n",
       "       [ 0,  0,  0, ..., 37, 30, 36],\n",
       "       [ 0,  0,  0, ..., 37, 30, 36],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 37, 22, 36],\n",
       "       [ 0,  0,  0, ..., 37, 30, 36],\n",
       "       [ 0,  0,  0, ..., 22, 29, 36]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  3, 23, 37,  2, 16],\n",
       "       [10,  3, 23, 37,  2, 16],\n",
       "       [10,  3, 23, 37, 30, 16],\n",
       "       ...,\n",
       "       [10, 17, 23, 37,  4, 16],\n",
       "       [10, 26, 23, 37, 30, 16],\n",
       "       [10, 17, 23, 37, 30, 16]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       503., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "This setup is based on the paper:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='http://arxiv.org/abs/1503.08895'> <img src='../Network.png' /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (a): A single layer version of our model. \n",
    "- (b): A three layer version of our model. In practice, we can constrain several of the embedding matrices to be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adarsh_iitd/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adarsh_iitd/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/adarsh_iitd/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.6821 - accuracy: 0.4652 - val_loss: 0.6899 - val_accuracy: 0.5750\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.6929 - accuracy: 0.5440 - val_loss: 0.6703 - val_accuracy: 0.5980\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.6580 - accuracy: 0.6084 - val_loss: 0.6228 - val_accuracy: 0.6690\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.6081 - accuracy: 0.6784 - val_loss: 0.5323 - val_accuracy: 0.7640\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5394 - accuracy: 0.7460 - val_loss: 0.4574 - val_accuracy: 0.8030\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.4708 - accuracy: 0.7906 - val_loss: 0.4412 - val_accuracy: 0.8240\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.4427 - accuracy: 0.8089 - val_loss: 0.4130 - val_accuracy: 0.8320\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.4135 - accuracy: 0.8270 - val_loss: 0.3912 - val_accuracy: 0.8300\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3909 - accuracy: 0.8385 - val_loss: 0.4091 - val_accuracy: 0.8320\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.3872 - accuracy: 0.8398 - val_loss: 0.3856 - val_accuracy: 0.8370\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3821 - accuracy: 0.8413 - val_loss: 0.3868 - val_accuracy: 0.8450\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3728 - accuracy: 0.8485 - val_loss: 0.3711 - val_accuracy: 0.8430\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3628 - accuracy: 0.8496 - val_loss: 0.3745 - val_accuracy: 0.8380\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3596 - accuracy: 0.8516 - val_loss: 0.3748 - val_accuracy: 0.8400\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3540 - accuracy: 0.8544 - val_loss: 0.3803 - val_accuracy: 0.8310\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3534 - accuracy: 0.8543 - val_loss: 0.3815 - val_accuracy: 0.8290\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3466 - accuracy: 0.8572 - val_loss: 0.3623 - val_accuracy: 0.8420\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3366 - accuracy: 0.8590 - val_loss: 0.3596 - val_accuracy: 0.8400\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3384 - accuracy: 0.8606 - val_loss: 0.3481 - val_accuracy: 0.8400\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3366 - accuracy: 0.8605 - val_loss: 0.3558 - val_accuracy: 0.8330\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3321 - accuracy: 0.8635 - val_loss: 0.3592 - val_accuracy: 0.8380\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3343 - accuracy: 0.8600 - val_loss: 0.3508 - val_accuracy: 0.8410\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3267 - accuracy: 0.8616 - val_loss: 0.3550 - val_accuracy: 0.8340\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3317 - accuracy: 0.8628 - val_loss: 0.3570 - val_accuracy: 0.8350\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3224 - accuracy: 0.8643 - val_loss: 0.3534 - val_accuracy: 0.8270\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.3231 - accuracy: 0.8636 - val_loss: 0.3631 - val_accuracy: 0.8390\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3196 - accuracy: 0.8685 - val_loss: 0.3367 - val_accuracy: 0.8480\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3168 - accuracy: 0.8646 - val_loss: 0.3663 - val_accuracy: 0.8330\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3180 - accuracy: 0.8650 - val_loss: 0.3603 - val_accuracy: 0.8380\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3132 - accuracy: 0.8702 - val_loss: 0.3552 - val_accuracy: 0.8390\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3155 - accuracy: 0.8686 - val_loss: 0.3520 - val_accuracy: 0.8420\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3149 - accuracy: 0.8656 - val_loss: 0.3425 - val_accuracy: 0.8400\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3127 - accuracy: 0.8676 - val_loss: 0.3567 - val_accuracy: 0.8360\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3091 - accuracy: 0.8700 - val_loss: 0.3470 - val_accuracy: 0.8470\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3104 - accuracy: 0.8704 - val_loss: 0.3544 - val_accuracy: 0.8440\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3101 - accuracy: 0.8688 - val_loss: 0.3421 - val_accuracy: 0.8390\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3014 - accuracy: 0.8727 - val_loss: 0.3539 - val_accuracy: 0.8440\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3046 - accuracy: 0.8701 - val_loss: 0.3541 - val_accuracy: 0.8470\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3077 - accuracy: 0.8684 - val_loss: 0.3390 - val_accuracy: 0.8520\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.3045 - accuracy: 0.8704 - val_loss: 0.3412 - val_accuracy: 0.8480\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3040 - accuracy: 0.8726 - val_loss: 0.3399 - val_accuracy: 0.8460\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3012 - accuracy: 0.8736 - val_loss: 0.3580 - val_accuracy: 0.8390\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2961 - accuracy: 0.8735 - val_loss: 0.3603 - val_accuracy: 0.8410\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2964 - accuracy: 0.8734 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.2957 - accuracy: 0.8754 - val_loss: 0.3377 - val_accuracy: 0.8480\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.2920 - accuracy: 0.8752 - val_loss: 0.3380 - val_accuracy: 0.8530\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2952 - accuracy: 0.8742 - val_loss: 0.3425 - val_accuracy: 0.8490\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2959 - accuracy: 0.8778 - val_loss: 0.3535 - val_accuracy: 0.8510\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2875 - accuracy: 0.8806 - val_loss: 0.3613 - val_accuracy: 0.8510\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2856 - accuracy: 0.8824 - val_loss: 0.3581 - val_accuracy: 0.8450\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2804 - accuracy: 0.8858 - val_loss: 0.3384 - val_accuracy: 0.8460\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.2815 - accuracy: 0.8841 - val_loss: 0.3411 - val_accuracy: 0.8490\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2739 - accuracy: 0.8834 - val_loss: 0.3207 - val_accuracy: 0.8540\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.2676 - accuracy: 0.8898 - val_loss: 0.3117 - val_accuracy: 0.8600\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2581 - accuracy: 0.8929 - val_loss: 0.3215 - val_accuracy: 0.8700\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.2547 - accuracy: 0.8942 - val_loss: 0.2991 - val_accuracy: 0.8670\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.2451 - accuracy: 0.8966 - val_loss: 0.2916 - val_accuracy: 0.8680\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.2399 - accuracy: 0.8986 - val_loss: 0.2779 - val_accuracy: 0.8850\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.2321 - accuracy: 0.9066 - val_loss: 0.2694 - val_accuracy: 0.8820\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2242 - accuracy: 0.9094 - val_loss: 0.2583 - val_accuracy: 0.8920\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2148 - accuracy: 0.9122 - val_loss: 0.2560 - val_accuracy: 0.8930\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2135 - accuracy: 0.9136 - val_loss: 0.2404 - val_accuracy: 0.9040\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2054 - accuracy: 0.9171 - val_loss: 0.2557 - val_accuracy: 0.8930\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.2005 - accuracy: 0.9199 - val_loss: 0.2424 - val_accuracy: 0.8950\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1958 - accuracy: 0.9211 - val_loss: 0.2343 - val_accuracy: 0.9040\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1934 - accuracy: 0.9202 - val_loss: 0.2258 - val_accuracy: 0.9070\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1901 - accuracy: 0.9220 - val_loss: 0.2378 - val_accuracy: 0.8990\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1940 - accuracy: 0.9227 - val_loss: 0.2241 - val_accuracy: 0.9030\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.1822 - accuracy: 0.9271 - val_loss: 0.2243 - val_accuracy: 0.9110\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.1826 - accuracy: 0.9239 - val_loss: 0.2498 - val_accuracy: 0.8980\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1785 - accuracy: 0.9288 - val_loss: 0.2247 - val_accuracy: 0.9020\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.1838 - accuracy: 0.9269 - val_loss: 0.2345 - val_accuracy: 0.9030\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1818 - accuracy: 0.9261 - val_loss: 0.2413 - val_accuracy: 0.9010\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1761 - accuracy: 0.9323 - val_loss: 0.2406 - val_accuracy: 0.9090\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1748 - accuracy: 0.9304 - val_loss: 0.2519 - val_accuracy: 0.9030\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1770 - accuracy: 0.9292 - val_loss: 0.2309 - val_accuracy: 0.8980\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1732 - accuracy: 0.9288 - val_loss: 0.2341 - val_accuracy: 0.9020\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1713 - accuracy: 0.9317 - val_loss: 0.2592 - val_accuracy: 0.9080\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1781 - accuracy: 0.9273 - val_loss: 0.2222 - val_accuracy: 0.9080\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1737 - accuracy: 0.9288 - val_loss: 0.2455 - val_accuracy: 0.9120\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1679 - accuracy: 0.9332 - val_loss: 0.2305 - val_accuracy: 0.9050\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1663 - accuracy: 0.9342 - val_loss: 0.2283 - val_accuracy: 0.9110\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1668 - accuracy: 0.9336 - val_loss: 0.2314 - val_accuracy: 0.9070\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 0.1658 - accuracy: 0.9364 - val_loss: 0.2294 - val_accuracy: 0.9020\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.1687 - accuracy: 0.9342 - val_loss: 0.2256 - val_accuracy: 0.9070\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1667 - accuracy: 0.9347 - val_loss: 0.2491 - val_accuracy: 0.9000\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1636 - accuracy: 0.9321 - val_loss: 0.2263 - val_accuracy: 0.9080\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1628 - accuracy: 0.9346 - val_loss: 0.2654 - val_accuracy: 0.9020\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1667 - accuracy: 0.9339 - val_loss: 0.2375 - val_accuracy: 0.9050\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1701 - accuracy: 0.9344 - val_loss: 0.2296 - val_accuracy: 0.9120\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1626 - accuracy: 0.9384 - val_loss: 0.2298 - val_accuracy: 0.9130\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1653 - accuracy: 0.9327 - val_loss: 0.2431 - val_accuracy: 0.9050\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1568 - accuracy: 0.9375 - val_loss: 0.2440 - val_accuracy: 0.9090\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1609 - accuracy: 0.9383 - val_loss: 0.2475 - val_accuracy: 0.9110\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1637 - accuracy: 0.9356 - val_loss: 0.2569 - val_accuracy: 0.9110\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1583 - accuracy: 0.9409 - val_loss: 0.2332 - val_accuracy: 0.9140\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1606 - accuracy: 0.9344 - val_loss: 0.2361 - val_accuracy: 0.9150\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.1566 - accuracy: 0.9383 - val_loss: 0.2187 - val_accuracy: 0.9130\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1575 - accuracy: 0.9401 - val_loss: 0.2163 - val_accuracy: 0.9170\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1541 - accuracy: 0.9401 - val_loss: 0.2488 - val_accuracy: 0.9060\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1512 - accuracy: 0.9421 - val_loss: 0.2373 - val_accuracy: 0.9110\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1546 - accuracy: 0.9382 - val_loss: 0.2277 - val_accuracy: 0.9100\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1505 - accuracy: 0.9385 - val_loss: 0.2439 - val_accuracy: 0.9080\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1536 - accuracy: 0.9400 - val_loss: 0.2466 - val_accuracy: 0.9170\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1566 - accuracy: 0.9393 - val_loss: 0.2434 - val_accuracy: 0.9090\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1488 - accuracy: 0.9444 - val_loss: 0.2610 - val_accuracy: 0.9100\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1562 - accuracy: 0.9375 - val_loss: 0.2545 - val_accuracy: 0.8980\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.1484 - accuracy: 0.9405 - val_loss: 0.2553 - val_accuracy: 0.9080\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1464 - accuracy: 0.9434 - val_loss: 0.2435 - val_accuracy: 0.9090\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1505 - accuracy: 0.9409 - val_loss: 0.2266 - val_accuracy: 0.9140\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1517 - accuracy: 0.9426 - val_loss: 0.2353 - val_accuracy: 0.9090\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1491 - accuracy: 0.9437 - val_loss: 0.2221 - val_accuracy: 0.9140\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1528 - accuracy: 0.9432 - val_loss: 0.2382 - val_accuracy: 0.9100\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1465 - accuracy: 0.9419 - val_loss: 0.2700 - val_accuracy: 0.9130\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1521 - accuracy: 0.9420 - val_loss: 0.2562 - val_accuracy: 0.9040\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1426 - accuracy: 0.9446 - val_loss: 0.2458 - val_accuracy: 0.9110\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1409 - accuracy: 0.9474 - val_loss: 0.2825 - val_accuracy: 0.9060\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1409 - accuracy: 0.9459 - val_loss: 0.2411 - val_accuracy: 0.9080\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.1423 - accuracy: 0.9456 - val_loss: 0.2474 - val_accuracy: 0.9050\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1445 - accuracy: 0.9458 - val_loss: 0.2384 - val_accuracy: 0.9190\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ChatBot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('ChatBot_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd81eXZ+PHPlT3JDhBWwl4CCoKoIA4UFEFbRdyrxVlXtWpb2/q0z+9ptbbaOnAUtwKOOhEBFVyo7L1nBmTvnZz798f9TTiEBA6Qk3Wu9+vFi5zvOvcd8b6+9xZjDEoppRSAX2snQCmlVNuhQUEppVQ9DQpKKaXqaVBQSilVT4OCUkqpehoUlFJK1dOgoHyKiLwiIn/x8No9InKet9OkVFuiQUEppVQ9DQpKtUMiEtDaaVAdkwYF1eY4zTYPiMg6ESkVkf+ISGcR+UxEikVksYjEuF0/VUQ2ikiBiCwRkUFu504WkVXOfXOBkAbfNUVE1jj3fi8iwzxM40UislpEikQkVUT+1OD8mc7zCpzzNzjHQ0XkCRHZKyKFIvKtc2yCiKQ18ns4z/n5TyLyroi8ISJFwA0iMlpEljnfsV9EnhaRILf7h4jIIhHJE5FMEfmtiHQRkTIRiXO7bqSIZItIoCd5Vx2bBgXVVv0cmAj0By4GPgN+C8Rj/93eBSAi/YG3gXuABGA+8LGIBDkF5AfA60As8I7zXJx7TwFmA7cAccDzwEciEuxB+kqB64Bo4CLgNhG5xHluTye9/3bSNAJY49z3d2AkcLqTpt8ALg9/J9OAd53vfBOoBe51fidjgXOB2500RAKLgQVAEtAX+MIYcwBYAkx3e+41wBxjTLWH6VAdmAYF1Vb92xiTaYxJB74BfjTGrDbGVAL/BU52rrsC+NQYs8gp1P4OhGIL3dOAQOBJY0y1MeZdYLnbd/wSeN4Y86MxptYY8ypQ6dx3RMaYJcaY9cYYlzFmHTYwneWcvhpYbIx52/neXGPMGhHxA24C7jbGpDvf+b2TJ08sM8Z84HxnuTFmpTHmB2NMjTFmDzao1aVhCnDAGPOEMabCGFNsjPnROfcqNhAgIv7AldjAqZQGBdVmZbr9XN7I5wjn5yRgb90JY4wLSAW6OefSzaGrPu51+7kX8Gun+aVARAqAHs59RyQiY0TkK6fZpRC4FfvGjvOMnY3cFo9tvmrsnCdSG6Shv4h8IiIHnCal/+dBGgA+BAaLSG9sbazQGPPTcaZJdTAaFFR7l4Et3AEQEcEWiOnAfqCbc6xOT7efU4H/NcZEu/0JM8a87cH3vgV8BPQwxkQBs4C670kF+jRyTw5Q0cS5UiDMLR/+2KYndw2XNH4O2AL0M8Z0wjavHS0NGGMqgHnYGs21aC1BudGgoNq7ecBFInKu01H6a2wT0PfAMqAGuEtEAkTkZ8Bot3tfBG513vpFRMKdDuRID743EsgzxlSIyGjgKrdzbwLnich053vjRGSEU4uZDfxDRJJExF9Exjp9GNuAEOf7A4HfA0fr24gEioASERkI3OZ27hOgi4jcIyLBIhIpImPczr8G3ABMBd7wIL/KR2hQUO2aMWYrtn3839g38YuBi40xVcaYKuBn2MIvH9v/8L7bvSuw/QpPO+d3ONd64nbgf0SkGPgDNjjVPXcfcCE2QOVhO5mHO6fvB9Zj+zbygL8BfsaYQueZL2FrOaXAIaORGnE/NhgVYwPcXLc0FGObhi4GDgDbgbPdzn+H7eBe5fRHKAWA6CY7SvkmEfkSeMsY81Jrp0W1HRoUlPJBInIqsAjbJ1Lc2ulRbYc2HynlY0TkVewchns0IKiGtKaglFKqntYUlFJK1Wt3i2rFx8eb5OTk1k6GUkq1KytXrswxxjSc+3KYdhcUkpOTWbFiRWsnQyml2hUR2Xv0q7T5SCmllBsNCkoppeppUFBKKVWv3fUpNKa6upq0tDQqKipaOyleFxISQvfu3QkM1P1QlFLNr0MEhbS0NCIjI0lOTubQBTE7FmMMubm5pKWlkZKS0trJUUp1QB2i+aiiooK4uLgOHRAARIS4uDifqBEppVpHhwgKQIcPCHV8JZ9KqdbRIZqPlFKqPat1Gb7ckkVGQTkje8UwqGsn/P1a5wVQg0IzKCgo4K233uL2228/pvsuvPBC3nrrLaKjo72UMqXU8cosqsDfT4iPONpeR8evtLKG91enM/vb3ezOKa0/Hh7kT0JkMGFBAQQG+FFV46KyppYZp/Zg5vhGN9RrNhoUmkFBQQHPPvvsYUGhtrYWf3//Ju+bP3++t5OmlAJ2ZpdQUV3LkKQoj65fvCmTu+esJiIkgPduO53uMfU7pVJRXcs7K1J5f3U6Q5I6cdXoXvTvHMHatAK+25HLhvRCtmYWs7+wgqjQQOLCg0iOC2dYjygGde1EgJ9QXevi6205vLcyjeLKGob3iObpq05mRI9oVu7NZ/W+AvJKqyirqqGq1hAc4EdwgB+dO4V461dUT4NCM3jooYfYuXMnI0aMIDAwkIiICLp27cqaNWvYtGkTl1xyCampqVRUVHD33Xczc+ZM4OCSHSUlJUyePJkzzzyT77//nm7duvHhhx8SGhrayjlTqu35bP1+3vhxL3+55CRS4sMPOZdVVMGSrdnsyysDoLy6lq+3ZbM9qwSAaSOS+P1Fg0mItG//Lpdhe1YJK/bm4TKQFBXChvQinvxiG4O7diI1r4zrZv/Ee7eejp+f8PqyPbz83R5yS6vo3zmCeSvSeOOHfYQE+lFR7UIEUuLDGZLUifMHd6aovIbc0ko27S9iwcYDh6Q1yN+PC0/qwrVjkzmlZ3R9f2H3mDCmjejm5d9i09rd0tmjRo0yDdc+2rx5M4MGDQLg0Y83simjqFm/c3BSJ/548ZAmz+/Zs4cpU6awYcMGlixZwkUXXcSGDRvqh43m5eURGxtLeXk5p556KkuXLiUuLu6QoNC3b19WrFjBiBEjmD59OlOnTuWaa65p9Pvc86tUe/b9zhye/WonN49L4ewBiYAtqD9cm876tCLS8suodRkuH9Wd8wZ15oVvdvHYgq2ALcDn3jKWHrFhLNmaxRMLt7E+vRAAP7GDMvxFGNkrhklDu5BbWsWsJTsJCfSjT2IEZZW1HCiqoLC8+rB0TRuRxN9+Poy1qQVcO/snuseEkl1USXFlDRMGJHDbWX0YnRJLYXk1761KZ09OKaf1juP0PnHEhAc1mtf80ip2ZJcggL+f0CsunNgmrvUGEVlpjBl1tOu0puAFo0ePPmQewb/+9S/++9//ApCamsr27duJi4s75J6UlBRGjBgBwMiRI9mzZ0+LpVepIzHGUFReQ1iwP4H+fhworOCV7/fw3qo0kuPCmDqiG2f0iaO0spb8sioGdokk0a2ZY19uGQXlVXSNCiUuPIiSqhpyiit5fuku5q5IJcBP+GFXLo9fPoxzBnTm3nlr+HJLFqGB/nSPCaWksoZb31hFdFggBWXVTB2exA1nJHPD7J+4+qUfOal7FJ+u20/v+HAenDSQswcmMKBzZKMj9aaNSOIfC7dRWF5NYmQwp/SK5pSeMZyaHEtIoD/7C8upcRlG9YpBRBjTO45/zTiZe+au5pyBidw+oS9Dux1sgooOC+LmMz2bMxQTHsSp4bEn/h/EyzpcUDjSG31LCQ8/WKVdsmQJixcvZtmyZYSFhTFhwoRG5xkEBx/szPL396e8vLxF0qo6nsKyavbkljIkqRMB/sc36rzWZfjPt7tYsOEAO7JKKKqoASA2PIjiimpqXYZzBiayL6+MRz7YcMi9AX7CBUO6cHrfOD5em8EPu/Ia/Q5/P+HWs/pw85kp3D1nNffOXUt8RDCF5VX8z7QhXHtaL0SEmloXizdn8uaP+xidHMud5/RFRHj1ptFc89KPLNqUya8n9mfmWb0JDmi6Dw+gT0IEz1x9SpPnu0Qd3mY/aWgXNg2ehF8rjQZqaR0uKLSGyMhIiosb39WwsLCQmJgYwsLC2LJlCz/88EMLp075ktS8Mma88APpBeXEhAVy9oBERiXHMrRbJ/olRhIa5I8xhiXbspm1ZCcb0gu57/wB3Hh6cn2hl5pXxr1z17Bibz4jekRz8fAkkuPCKa2qIau4ksiQAK4Z04sesWEYY9hyoJj16YVEhwYSGRLIV1uzmLs8lU/X76dHbCgPXDCAvokRHCisILekksiQQGLCgxjRI4q+iZEAvHzjqTzwzjpWp+bz4nVjOblnTH2eAvz9mDS0K5OGdj0kryf3jOHTu8YR4C+HdAR7g68EBNCg0Czi4uI444wzGDp0KKGhoXTu3Ln+3KRJk5g1axbDhg1jwIABnHbaaa2YUtXeuFyGrOLKQ95gP16bwYvf7GJIUifOG9SZ0SmxRIYEsi+3jBkvLKO0qpa/XDKUVXvz+XJrFu+vTq+/NyjAj9BAfwrLq+kaFcJJ3aP48yebWLI1i7MHJLJ8Tx5fb8vGT4QnrxjBtBFJR5wwKSIM6tqJQV071R8b2yeO+yb2Z1d2KQO7RHpUoAYH+POvK0/GGHNMEzSTG3Q0qxPX4TqafYGv5ddXpeWXcd/ctfy0J4/zB3fmrnP78cHqdF76djcp8eFkF1dSUmmbdWLCAqlxGfz9hDduHlPf7m2MITWvnI0ZhezKKaWoopriihpG9oxh6ogkAvyEt37ax58/2URFtYvuMaGc1juOu8/tR49Y7759q5alHc1KtTMulyEtv5yMwnI27y/iHwu3YYCrx/TkozUZLNyUCcANpyfz2wsHYTD8uCuPjRlFpOaXUVhezR0T+jI46eBbu4jQMy6MnnFNF/BXj+nFpCFdqKxxkRStw6B9nQYFpVqIMYZV+/JZm1rIxowiSitr6BUfRlJUKGvTCli6NZvc0qr660f2iuHJK0bQIzaM31wwkNeW7SElIZwpw5LqrxnfP4Hx/Y+67e5RxXlx1q5qJrU14O/9IluDglJeVlFdy4dr0nnpm931k6jiI4LpFBrAl1uyqKp1ERMWyPj+CZzWO44eMWF0jQ4hJS68vj0+KiyQX53brzWz0b4YA8eyeOSxXt/SXLXw3Okw4io48x6vfpUGBaW8xOUyfLAmncc/38r+wgoGde3E3y8fzvh+8fXj+GtdhuziShIig1ttAbR2q6YK8ndDSDREOoM7MlbDx/dAQAjcOB/8jjxEFYDKYvjPBdDtFJj677YZHLbOh5ytEJPs9a/SoKBUM6qormVdWiGr9uXzyboMNqQXcVK3KB67bBhn9o0/bGSNv580OjbeJ5Tm2oKuJAv6nQ9BHnRsVxTB8pdg7RzI3QGmFhDoMRri+sHatyAoAiqLYM1bcMq1R3/mgocha6P90+UkGHOL53kwBpY9Dak/wYWPQ2QXe3zN27D+HTj7t9Dd6dstzYF9P8CAC8HvGOePLHsGonvCwCnHdt9x0KCgVDPYX1jOK9/v4a0f91HsTPTqkxDOP68YzrTh3Y5/nHv+Xtj6GYz+pWdvvSeiugK+fhxWvw6XPAd9z7XHK4th2bMweCokNsOot9pqeOcG2PLJwWODLobprx/6ll6WB9sWQPpKW/jWVsLmj6GiEJLHwaApEN8fClJh80ew5k045TqY+Ci8OR2+/DMMuQSCI2Hv97B9IcT2hvgBkDQCAoJhy3yb3zPuhpzt8Plvoetw6DEGijIgNBqCmhj2WlUKH94BG/8L4gdpy+Gyl+3nn54H/yB46TwYc6vN14qXoaYcJv4ZzrjLPqOiCH58HobPgOgejX9P2krYtwwu+D/tU2gvjnfpbIAnn3ySmTNnEhamw//ao40Zhbz0zW4+XpuByxgmD+3KtBFJjOwVc+Kdt5Ul8NZ0yN5im0eGXOrZfWvets0o5//ZFnxNqSq1BWVtNdRUwHdP2bfvsHiYdx3c8CnE9II3LoP0FTZgjLsPxv36yM8FG2DSV0Kv0w8t6I2xzTtbPrEFcfJ4yFgFX/0vfP+vQwvnHV/YmkBwFPg7e5KnjIcz77NNPe7OesDmo+66Sf8HL50L3/4TQmNh0SNgXAevD4qE/ufD7q+h80lw9u+hugxePBve+DkgUFVsg8NNnx/MQ9F+2PQBZG+F3Ushfw+c96gNoHOuhpcn2etOuwPG32/z9eNzIP4w7AoozbbBqs85NqDNvcY+58fn4PJXIWWcDRSpP9nAFR4PPzwDwZ3g5MbXQmtuOk+hGbgviHes6hbFi4+P9/ie1s6vss1Ed761isWbswgP8mf6qT246YyUYxvbX9cUsuo1mPAwDL/i4Dlj4N2bbAEUngDhiXDrN0dv797zLbw61RamfSfCFa9DYCPDTMsL4M3LIe2ng8eie8LFT0HCIPjPRKiphIjOtolnypO28Fo3FxIHwxVvQFwfOyLmi0dh1xK48m2I6u6k/Ub7xjzmVvuGW9dc8uX/wtePwVkPwdkPH8zrOzfYt/2RN8DqNyAwDEbdZGsnXUccXzv/e7+wTTgAg6bCtKehLBcyN8H2z2HLp1BVBr/8EjoPttdlbbHpC4u3gXLVq3DlHBgw2f4+Zp0JOdtsP0biIBj/wMEaVVkeLP4jpJwFJ112MB05220fR3QP24T07FiISISEgbDhXTjnEVg3zwbk5DNsE1Ntlf0dDJ8BK1+F026DC/732H8Hbjydp+DVoCAik4CnAH/gJWPMXxucjwFmA32ACuAmY8wRS9a2GBRmzJjBhx9+yIABA5g4cSKJiYnMmzePyspKLr30Uh599FFKS0uZPn06aWlp1NbW8sgjj5CZmcn999/PgAEDiI+P56uvvvLo+1o7vwoeem8dc5anct/E/lx/ejJRoYGHXlCwD75/2hZ8oTGHP2DdPJh/v20KCU+wAeLmhfbtEGwb8ue/hXP/aAvmD2+Hq+ZB/wsOPqM01xZQwRHQeSgUH4Dnx0NIFJx6s20rTz7TFmrBEYfe98altnC85FnoNtIej+p+sAaQvRX+c74tGGe8CX3Ps8e3LYT/zrRv3Rf9wwa03UttU0lsH7hpgW3L//xh+9z0lbZJ56TL4ZsnbPA4+drDO3Qri+HFc2x+hvwMJv/NFpwnojANXv8ZDJtuazcNA4ur1vY9NPbfB2zN4+lTbfPRLd/Y9H/1F5jxtg0Sx9shve1zWwMEOPcPNm0VRfDJvbaG13+SrRFt+sD+OwG4e40N2ieg1YOCiPgD24CJQBqwHLjSGLPJ7ZrHgRJjzKMiMhB4xhhz7pGee9Sg8NlDcGB9c2bFdj5N/muTp91rCgsXLuTdd9/l+eefxxjD1KlT+c1vfkN2djYLFizgxRdfBOyaSFFRUVpTaIfmLt/Hg++t546z+/DABQMbv+jtK+2IkTG3Hf5vJ2uLLby7DocLH4OoHvD8WfZt+toP4Ou/2w7TARfZAtlVA/86xXZi3rTA1i6+eQJKMg8+M7qXLdAL0+2bb+JAW6D891b7RjrjTYhNgbQV9lhhqn3b7zex6Yzm7rQFY2KDPObvgTnXQOZ6Gwym/NPm4Y2f22szN9lCc/rrtvnkm7/b+yI6w+m/sr+TxtrGizPtaKKebWgpmHXz4P1fwjm/h6WPw8AL4fJXTvy53/zD/ncd/8CRg0v+HhvEu4884a9sCzOaRwM7jDG7nATNAaYBm9yuGQz8H4AxZouIJItIZ2NM5mFPaycWLlzIwoULOfnkkwEoKSlh+/btjBs3jvvvv58HH3yQKVOmMG7cuFZOqTpW5VW1LNqcySMfbuTMvvHcN3FA4xfuWmIDQmQSLH/RvrXHO3MMaqrsm3ZwhC2o696Gp79m26P/PdJ2KI+7/2CB4R9oOybn32/HqmdvsU0Up99l26VLDtgO2L3f2yaSukJ82HTbJv3OjfDCBDvqZe3b0CkJrnnP1iKOJK6JbR9jkm2t5vt/Q7/zDtY0Lp0F791sawyXPGuD3LmP2H6J2moYcTUEHmGkVWTng0NL24qhP7f9El/+xbbrT2r65fCYjLvPs+tikltkGKo7bwaFbkCq2+c0YEyDa9YCPwO+FZHRQC+gO3BIUBCRmcBMgJ49j1KFOsIbfUswxvDwww9zyy2HD2tbuXIl8+fP5+GHH+b888/nD3/4QyukUB2LmloXS7dl8+7KNL7amkVFtYvkuDCemjGi8XkFrlpY8Ftb1b9hvm0/Xvh7uGquPf/1Y7B/LVzx5qHNI91HwtSnbRv4eX+CLkMPfe7J19q3y5Is+NmLtjnG/Q3zlOsaz0Cfc2DmEtsJuvZtO4rpnEcgpFPj13sqKAwmPHjosZMus7WB2N62CetoaWsP/PxtE8/bM+x/l7ohpx2YN4NCY3Wihm1VfwWeEpE1wHpgNVBz2E3GvAC8ALb5qJnTecLcl86+4IILeOSRR7j66quJiIggPT2dwMBAampqiI2N5ZprriEiIoJXXnnlkHuPpflIedf2zGK7HEVaIYs3ZZJVXElceBCXj+zBpKFdGJMS2/g+BbXVtmkna6NtYojuYUegLP4jLPqjDQa7ltg35kGNjDcffsWhnc3uAkPglqW2iSjEs32G68Wm2Cal4gxbYHtTSgesAQ+YDPdttjUsH+DNoJAGuA+87Q5kuF9gjCkCbgQQO6tnt/OnXXFfOnvy5MlcddVVjB07FoCIiAjeeOMNduzYwQMPPICfnx+BgYE899xzAMycOZPJkyfTtWtXjzualXcs25nLU19sq98UJjIkgDEpcVw+qjvnDEwksKkNa/Yug0/vs52krhroORYGX2LPnXYbrHwZvnsS4vraZoMzPWw6aOhEOl4DQ7wfEDoyHwkI4N2O5gBsR/O5QDq2o/kqY8xGt2uigTJjTJWI/BIYZ4w5Yl2zLY4+amm+ll9vq6yp5Z45a/hswwESIoOZOa435w5KJNlt7aEmVZXBs2NsHfikyyBhgH2zdH+bL8qwo2vi+7fNJRSUT2j1jmZjTI2I3Al8jh2SOtsYs1FEbnXOzwIGAa+JSC22A/pmb6VH+baK6lp255TSLzHikKaf6loXd761mkWbMrn//P78YlxvQgKPYebw0r/Z4ac3zLdjzBvjQ2+Zqv3z6oxmY8x8YH6DY7Pcfl4G6NKPymtqXYb3Vqbxj0XbOFBUQWRwAGP7xDEkKYqu0SF8tSWLRZsyeXTqEK4/PfnoD1z9hl2W4NRfQNdhdt2bk69pOiAo1c50mGUujnUbv/aqvc1Abw01tS5W7M3nq61ZLNyYye6cUkb0iOae8/qxNq2Qb3dk129YA/D7iwZ5FhCMgW+ftGPHP74LEAiLtWvZKNVBdIigEBISQm5uLnFxcR06MBhjyM3NJSTER1fVPIriimrmLk/l5e/2kF5QTqC/MKpXLA9cMIDJQ7sgIswYba+trKkls7ASlzGe7/Obvgpyt8PF/4JO3ewchFOut4FBqQ6iQwSF7t27k5aWRnZ2dmsnxetCQkLo3r17ayejTamqcfHasj089cV2iitqGJ0cy28vHMRZAxKICG78n3hwgP8Rt6hs1Nq37Ro2Qy6xHcn9zjvxxCvVxnSIoBAYGEhKSkprJ0OdgFqXITWvjANFFfj7Cf5+QoDzd2FZNYs2Z7JwYyZZxRUEB/gTGuRPclwYfRIi+Gl3HrtyShnfP4FfT+zP8B7RzZ/Amiq7eNnAi459noBS7UiHCAqqbXG5DHOWpzJn+T5O7xPP1WN6Nrp6aEZBOR+tzWD++v1sOVBMVY2rkadZQQF+jO+XwNQRSVRWuyiprGZPThkLN2USFx7E7BtGcfaARO81H25fCOX5MPxK7zxfqTZCg4IPKq6oJtDfr9Ghl6v35fN/87fQOSqEsb3jOGtAAt2iD116uarGxRebM3l/dTp7c0spKq+h1hhO6RnN6JQ45q/fz8q9+fROCOeFr3fy/Nc7OaNPPOP7x3NKzxjWpBawYMMBVuzNB2B4j2huOD2ZvgkRdIsJxRiodrlwuQw1LkOQvx+jU2IJb6IpqFkVpsP8B+xCcSOuOrhq6Nq37fLVvc/2fhqUakUdYj8F5bmvt2Vz15zVhAb68+jUIZw/5OBaLh+uSeeBd9cRE2aXgc4sqsTfT5g6PImZ43uTW1LFgo37mb/+AHmlVXTpFMLwHlF0Cgmk1mX4aU8eafnlxIQF8ruLBvPzU7qxv7CCt3/ax4INB+o3rQcY3LUTk4d2YeqIJHrFedjR2xLmXH1wR7DIJLtsQ+4Ou6Txabef8Jr2SrWWVl8621s0KFhVNS6CApre59UYw66cUlbuzcdPhKSoEFbty+eJRdvolxiBnwhbDhQzrl88CRHBZJdU8s32HEanxDLrmpHEhAWyM7uUucv38eaP+yirqgUgNNCfcwYlcvnI7ozrl3DYonDpBeVEhQY22sF7oLCC1fvyGZIUdeydvC1h8ycw92q78FnX4XYButyddoXTxMFw1m90pJFqtzQodFDr0gp4+ssdLNyUyTkDE/nthQPpmxhJYVk1P+3JY31aARszilibVkBOSdVh908Z1pW//XwYQQF+/Ofb3bz83W4C/f2ICg1kbO84fjNp4GHBJq+0ig9Wp9M9JpTx/ROObcZve1FZDM+MsZ3It3x9cFtHpToIDQrtmDGGTfuL+H5HLst25bI+vbB+cl52cSWdQgKYNLQLn60/QFl1LX0TItiWVYwx4CfQNzGCod2iODU5llOTY/D382N/YTkYGNunY8/lOC7G2AXtVsyGmxdBj9GtnSKlml2rr32kjt3KvfnMW57Kkm1ZZBZVAtA7IZwJ/RMICvCj1mXonRDOlaN7EhkSyIOTBvLvL3ewI6uEC0/qytg+cZzULYrQoMPf5FM8naDla4yBz39nA8LYOzUgKJ+nQaGV7MkpZfmePPz9hJpaw7ur0vhpdx4RwQGM7x/PhAGJjO+XQJeopmcvx0UE86epQ1ow1R2MywXzf20DwuhbdLkKpdCg0KJczgid2d/uZtHmTNxb7pKiQnhkymBmnNqjZYZetgZXLWz9zC4e19Rm6Z7YuwyW/hVG3QyDpx7fMyqK4L+32G0zz7jHdi5rs5pSGhS8qdZl2JtbytYDxXy/M5fPNx4gq7iS6LBA7pjQl0tO7kagv1DrMvSIDWt6E5eOoDwf3vsF7Fhsx/tf+DgMnnZsBbExsOI/8NmDgNhdzAZOgUEX28J9xxdQXWavje9vt8BsbH/b7G0w5yrI2wWTH4PRMzWd6bPqAAAcwElEQVQgKOXQoOAlK/fmcfOrKygoqwYgJNCPCf0TuWBoZy4Y0oWwoFb61RsDX/8d4nrbTclPxIH1drRO9FH2zc5YA+/cAIVpcPbvYcvH8M71diLYsCug/wVHHupZWQI7FsG6ebbw73c+XDILVr8GS/5q5xWEJ9r8RCSCccHy/8DsyXD9xxDf1z4nb5dd5XTNWzbd13909M3rlfIxOvqoue34gpy0HcxYGk1NWCK3T+jLwK6R9O8c2TaGcq57B97/BYTFw32bDs7YPVZ5u+GZ0bZJaNgVdpvJ+AZbY6SvhK+fgK2f2g3dp78OPcdAbQ38+Bz88BwUpYNfAJz/F7t1pTtj4MdZsPhPUFNh0zx6pt332M/5XRakQkkmJJ188BjAgQ3w2jQQP+h1OuRsh+zN4Bdo9z8Yf79ufqN8ig5JbQ3pKzGzJyG1VbgQqrqeSsjFj9kCyxM1VXbmbNKI4y+sj6QwDZ49HYIjbGH8sxdh2PSmry8+AMX7octw8GvQtDXvOti+yC4FsfpNqK2ys33H3Grf1L94FL57CkKi7bExtxxeGzAGMlbB0sdg2wL42Usw7HJ7rrocPr4H1s2BfhfAGXfZvY/9jiGwZm+z6aypsNtkdh0OI2+ETl09f4ZSHYQGhRZSUV3LxowiNu/czYXfX0FFjeHemjv556kFJO2YC+V5cPFTMHyGnR276ysYNA0iEg5/2Bd/hm/+DsGdbBNJwkAQbMF6ynWHB4qMNfDtP2wwuWw2BB1hlrDLBa9fAmkr4NZv4K3pEBoLv1h0+LV5u22BvsYp7CO6wKApdpmHuD6w93t4eTJMeBgmPAQl2fDJPbYZZ9gVUJoNO7+EUTfBxP+B4Mgj/xKrK+CNn0Pqj/Z3VbAP1s+zzT0TfgvjHzg8KCmljokGBS8zxnDfvLV8vDYDl6uWVwP/ymj/rTyT8gynjzuP03rH2cLynRtg77e2wzN/j7055Sy49oNDC7ryAnjyJPs2G5Ns287Lcg+eH3Ip/Hy2vacw3RbC2xfaAFJZbDeLn/46+DfRV7HqNfjoVzDlSRh1Iyx7Fj5/2M7e7TIMlr8Emz6E7K1QmgX+QTDiajtuf+tntlZgXDDhQdj8MRRnwq9WQJAz/8Hlgq8fhyX/z9570RM2kHmqvABmT7JNPIht8jnjHuh/vufPUEo1SYOCl32+8QC3vL6Sa0ZEcVfBYyQeWGp35Bp5/aEX1lbDV/8P9q+xb//V5bZpZdLf4LRbD1739d/hyz/bQrrrcNu04qqx5354Fhb9AU67w76xz7vOPufMe2H0L20H7Pz7bdPImFshZ5vtSO19lr2/ugL+fQpEdoVfLLYjbcrz4YlBduSOcdm9Ajo7QSlxoO20dW9zLz5gVw/d/JH9fOkLMPyKw38xe5fZ5qkuJx37L7UkC3Z+BX3Oth3GSqlmo0GhuRUfsM0gQeHU1Lq44MmvSandw4sh/0IK9sLkv9nN3I/GGHjrCti91AaAhAFQVWprCUmnwDXvNn7Pgodt56z4QUwKzHjLFt51Fj9qm5LcXfYyDP2Z7dBd8BBc9yH0nnDw/Ee/sjUIBM75HYy7/+hDMzd/AgfWwVkPaZOOUu2IBoXmtH8d/Od8wEDf89hQk4Rr2yKG+e22QyGnvwa9xnr+vOJMeG7swU7Y0mz4+jG46XPoeVrj97hc8Om9dtLVlH9CaIPdxYyBDe/Z0UDxfW0QObABbvjYBqHEQXZ4prvsbfDh7bbNvv8Fx/QrUUq1LxoUmkt5Pjx/lm0GGngRri2f4Fe8n62BA+l/1lXI8BkQ2fnYn7trCcz/DeRstZ97nQk3ftp86S7KgOfHQ0Wh7Sy+eTH0OLX5nq+Uald0Qbzm4HLB+zNtAXvjfOgxmlejbuMfn6xi9g3nIsknsLZ+7wlw50+2Y3fHYtvf0Jw6Jdnmo9emQf9JGhCUUh7RoHAky1+yI3wu/Hv96pkfrD1Az6QunHoiAcFdwgD7xxtSxtl+i5he3nm+UqrD0Z7CI1k/z47GcTqQ9+WWsTa1gIuHt6OZsF2GHn2egFJKOTQoNKUk2070GnBR/Yicj9dlAHb3MqWU6og0KDRlxyLAHDIq5+O1GYzsFUP3mDa4v7BSSjUDDQpN2bbATvbqOhyA7ZnFbDlQzMVaS1BKdWAaFBpTUwU7vrQjguqajtZm4CdwoQYFpVQHpkGhMfu+h6piO5QTu87Rx+v2M7ZPHImRTW+PqZRS7Z0GhcZs+xz8g+vXDtqYUcTunFKmDGtHo46UUuo4eDUoiMgkEdkqIjtE5KFGzkeJyMcislZENorIjd5Mj0eMsauCpoyvXwH043UZBPgJk4d2aeXEKaWUd3ktKIiIP/AMMBkYDFwpIoMbXHYHsMkYMxyYADwhIkHeSpNHCtMgfzf0mwjYpqNP1u7nzH7xRIe1btKUUsrbvFlTGA3sMMbsMsZUAXOAaQ2uMUCkiAgQAeQBNV5M09FlO2sROUs/r04tIL2gXJuOlFI+wZtBoRuQ6vY5zTnm7mlgEJABrAfuNsa4Gj5IRGaKyAoRWZGdne2t9Fp1C9TF26UnPlm7nyB/P84fchyL3imlVDvjzaDQ2ML8DZdkvQBYAyQBI4CnRaTTYTcZ84IxZpQxZlRCQiPbWDan7K0QFgfhcbhchk/XZ3DWgAQ6hQR693uVUqoN8GZQSAN6uH3ujq0RuLsReN9YO4DdwEBaU862+lrC8j15ZBZV6rIWSimf4c2gsBzoJyIpTufxDOCjBtfsA84FEJHOwABglxfTdHTZWyGhPwBfbs0iyN+P8wZp05FSyjd4belsY0yNiNwJfA74A7ONMRtF5Fbn/Czgz8ArIrIe29z0oDEmx1tpOqrSHCjPq68p7MouJTk+jPBgXWFcKeUbvFraGWPmA/MbHJvl9nMG0My7y5yAupFHTk1hb24pveLCWzFBSinVsnRGszu3kUcul2FvbhnJcboiqlLKd2hQcJe9DQLDIao7mcUVVNa4tKaglPIpGhTc5WyF+H4gwp6cMgCSNSgopXyIBgV32dvq90vem1sKQC9tPlJK+RANCnUqS6AoDeKdTua8MgL9ha5RulS2Usp3aFCok7PN/u1WU+gRE0aAv/6KlFK+Q0u8OnVBwZmjsCenTJuOlFI+R4NCneyt4BcAsSkYY3SOglLKJ2lQqJO/G2KSwT+QnJIqSqtqdY6CUsrnaFCoU5ZnV0fFfeSR1hSUUr5Fg0KdigIIiQZgT66do6B9CkopX6NBoU5FIYREAbAvtxQ/ge4xGhSUUr7Fo6AgIu+JyEUi0nGDSHkBhB6sKXSLCSUooONmVymlGuNpqfcccBWwXUT+KiKtuxFOc3O5nJqCDQp7c0t1eQullE/yKCgYYxYbY64GTgH2AItE5HsRuVFE2v8+lZVFgDmkpqD9CUopX+Rx+4iIxAE3AL8AVgNPYYPEIq+krCVVFNi/Q6IpLKumsLyaXrFaU1BK+R6PNtkRkfexeye/DlxsjNnvnJorIiu8lbgWU14XFKI4UFQBQNdoXfNIKeV7PN157WljzJeNnTDGjGrG9LSOikL7d2g02cWVAMRHBLdigpRSqnV42nw0SESi6z6ISIyI3O6lNLU8t+ajnBIbFBIiNSgopXyPp0Hhl8aYgroPxph84JfeSVIrqGs+cqspaFBQSvkiT4OCn4hI3QcR8QeCvJOkVuBWU8guqSQowI/IYE9b1pRSquPwtOT7HJgnIrMAA9wKLPBaqlpaeQGIPwSFk1NcSUJEMG4xUCmlfIanQeFB4BbgNkCAhcBL3kpUi6sotHMURMguqSRem46UUj7Ko6BgjHFhZzU/593ktBK3xfCyiyt1zSOllM/ydO2jfiLyrohsEpFddX+8nbgW47buUU5JpXYyK6V8lqcdzS9jawk1wNnAa9iJbB2DU1OoqXWRW1pFQkTH6UNXSqlj4WlQCDXGfAGIMWavMeZPwDneS1YLKy+AkCjyyqowRoejKqV8l6cdzRXOstnbReROIB1I9F6yWlhFgc5mVkopPK8p3AOEAXcBI4FrgOu9lagWZUz9stk6cU0p5euOWlNwJqpNN8Y8AJQAN3o9VS2pqhRcNRAaTU5JFaBBQSnlu45aUzDG1AIjpaPO5nKfzazNR0opH+dpn8Jq4EMReQcorTtojHnfK6lqSW7LZufsryQsyJ9wXeJCKeWjPC39YoFcDh1xZIAjBgURmYTdjMcfeMkY89cG5x8ArnZLyyAgwRiT52G6TlzFoYvhadORUsqXeTqj+Zj7EZy+iGeAiUAasFxEPjLGbHJ77uPA4871FwP3tmhAALeaQjTZxRXadKSU8mme7rz2MrZmcAhjzE1HuG00sMMYs8t5xhxgGrCpieuvBN72JD3Nym2DnZySvfRJiGjxJCilVFvh6ZDUT4BPnT9fAJ2wI5GOpBuQ6vY5zTl2GBEJAyYB7zVxfqaIrBCRFdnZ2R4m2UMNls2Oj9TZzEop3+Vp89EhhbWIvA0sPsptjY1WOqy24bgY+K6ppiNjzAvACwCjRo1q6hnHp7wAEKoCIigoqyYhQvdmVkr5Lk9rCg31A3oe5Zo0oIfb5+5ARhPXzqA1mo7AWfeoE7ll1YDOUVBK+TZP+xSKOfQt/wB2j4UjWQ70E5EU7LIYM4CrGnl2FHAWdpZ0yysvaDBHQZuPlFK+y9Pmo8hjfbAxpsZZJ+lz7JDU2caYjSJyq3N+lnPppcBCY0xpE4/yLmeDnZwSXeJCKaU8rSlcCnxpjCl0PkcDE4wxHxzpPmPMfGB+g2OzGnx+BXjF8yQ3s4qGNQUNCkop3+Vpn8If6wICgDGmAPijd5LUwpxls3UxPKWU8jwoNHZdx1gLwlk2O6ekisiQAEIC/Vs7RUop1Wo8DQorROQfItJHRHqLyD+Bld5MWItx62hO0KYjpZSP8zQo/AqoAuYC84By4A5vJarFVJdDbaVd96ikUvsTlFI+z9PRR6XAQ15OS8urW+IixI4+GtjlmAdZKaVUh+JRTUFEFjkjjuo+x4jI595LVgtxXza7WGsKSinlafNRvDPiCABjTD4dYY/m8nwAqoOiKaqoIS5cg4JSyrd5GhRcIlK/rIWIJNP0OkbtR6ldXK/ALwpAF8NTSvk8T4eV/g74VkSWOp/HAzO9k6QWVJoFQI6JArK0+Ugp5fM87WheICKjsIFgDfAhdgRS+1aaA0BmTTigs5mVUsrTZS5+AdyNXel0DXAasIxDt+dsf0qyIDSWrDIXgM5TUEr5PE/7FO4GTgX2GmPOBk4Gmnm3m1ZQmg3hCfWL4WmfglLK13kaFCqMMRUAIhJsjNkCDPBeslpIaTZEJJJbUkVooD9hQR1j5Q6llDpenpaCac48hQ+ARSKST9Mb5rQfpdnQ5SRydBtOpZQCPO9ovtT58U8i8hUQBSzwWqpaSkk2hCeSk6ET15RSCo5jpVNjzNKjX9UO1FRCZaHtUyiuomdcWGunSCmlWt3x7tHc/jkT14iwHc1aU1BKKQ0K1IbFk1dWRYLuzayUUj4cFEpsUCjyi8EYiNOaglJK+XBQcGoKuXQCdDazUkqBTwcFu+5RpqsuKGjzkVJK+XBQyIHAMLIq7J7M8ZFaU1BKKd8NCiVZ9cNRQZuPlFIKfDko1K17VFpJkL8fnUJ0iQullPLtoBCRSE5xFXERQYhIa6dIKaVanW8HhfB4nbimlFJufDMouFy2ozk80QkKOvJIKaXAV4NCeT6Y2vq9FLSmoJRSlm8GBWeOgis8gdySKh2OqpRSDh8NCnY2c1lADDUuQ1y4Nh8ppRT4alAosTWFXIkCIEFrCkopBXg5KIjIJBHZKiI7ROShJq6ZICJrRGSjiLTMXg2lOQBk1kYCOnFNKaXqeG3Gloj4A88AE4E0YLmIfGSM2eR2TTTwLDDJGLNPRBK9lZ5DlGaB+LO/KhSARK0pKKUU4N2awmhghzFmlzGmCpgDTGtwzVXA+8aYfQDGmCwvpucgZ45Cdkk1AImRIS3ytUop1dZ5Myh0A1LdPqc5x9z1B2JEZImIrBSR67yYnoOcvZmziisJCvCjU6gucaGUUuDF5iOgsXUjTCPfPxI4FwgFlonID8aYbYc8SGQmMBOgZ8+eJ56ygn3QqStZRRUkRgbrEhdKKeXwZk0hDejh9rk7kNHINQuMMaXGmBzga2B4wwcZY14wxowyxoxKSEg4sVSVZEHWRuh1OlnFldqfoJRSbrwZFJYD/UQkRUSCgBnARw2u+RAYJyIBIhIGjAE2ezFNsGuJ/bv32WQXV+pwVKWUcuO1oGCMqQHuBD7HFvTzjDEbReRWEbnVuWYzsABYB/wEvGSM2eCtNAGw8ysIjYWuw52agnYyK6VUHa/2sBpj5gPzGxyb1eDz48Dj3kyH25fBzi+h91lU1EJhebU2HymllBvfmtGcvQVKDtQ3HQEkdtKgoJRSdXwrKOz8yv7d52yyS5ygoM1HSilVz8eCwpcQ1xeie5JVZIOCdjQrpdRBvhMUaiph73fQ5xwAsosrAF3iQiml3PlOUEj9EarLoPfZAGQVV+InEKeL4SmlVD3fCQr+wdB/EiSfCUB2cSVxEcH4++lsZqWUquM7i/70HANXza3/qLOZlVLqcL5TU2ggq7hCg4JSSjXgu0GhSJe4UEqphnwyKNS6DDklusSFUko15JNBIa+0CpfR2cxKKdWQTwaFLJ2joJRSjfLRoFA3m1mbj5RSyp1PBoXsorp1j7SmoJRS7nwzKJToukdKKdUYnwwKWUUVdAoJICTQv7WTopRSbYpvBoXiShI7aX+CUko15JNBIbu4kgRdCE8ppQ7jk0Ehr7SKuIig1k6GUkq1Ob4ZFMqqiA3XoKCUUg35XFCoqXVRUFatQUEppRrhc0GhoLwaQIOCUko1wueCQn5pFQAxYRoUlFKqIZ8LCnlOUNCaglJKHU6DglJKqXq+FxTKNCgopVRTfC4o1PUpRIcFtnJKlFKq7fG5oJBbWkVEcADBAbrukVJKNeRzQSG/VCeuKaVUU3wuKOSVVROjQUEppRrle0GhtJJY7U9QSqlG+VxQyC+tJjZcV0hVSqnGeDUoiMgkEdkqIjtE5KFGzk8QkUIRWeP8+YM30wN2nkJsuNYUlFKqMQHeerCI+APPABOBNGC5iHxkjNnU4NJvjDFTvJUOd+VVtZRX12qfglJKNcGbNYXRwA5jzC5jTBUwB5jmxe87qvqJa7rukVJKNcqbQaEbkOr2Oc051tBYEVkrIp+JyBAvpqd+4poOSVVKqcZ5rfkIkEaOmQafVwG9jDElInIh8AHQ77AHicwEZgL07NnzuBOk6x4ppdSRebOmkAb0cPvcHchwv8AYU2SMKXF+ng8Eikh8wwcZY14wxowyxoxKSEg47gTVBQXtU1BKqcZ5MygsB/qJSIqIBAEzgI/cLxCRLiIizs+jnfTkeitBdUEhToOCUko1ymvNR8aYGhG5E/gc8AdmG2M2isitzvlZwGXAbSJSA5QDM4wxDZuYmk1+WRV+Ap1CdEiqUko1xpt9CnVNQvMbHJvl9vPTwNPeTIO73NIqYsKC8PNrrLtDKaWUT81ozi+t0v4EpZQ6Ap8KCnm6QqpSSh2RTwWF/LIqnbimlFJH4FNBIU+bj5RS6oh8Jii4XIb8smpdDE8ppY7AZ4JCcUUNtS6jy2YrpdQR+ExQyC2tBNCaglJKHYHPBIV8Z4XUGO1oVkqpJvlMUMgrrQYgTpuPlFKqST4TFGLCApk8tAudO2lQUEqppnh1mYu2ZFRyLKOSY1s7GUop1ab5TE1BKaXU0WlQUEopVU+DglJKqXoaFJRSStXToKCUUqqeBgWllFL1NCgopZSqp0FBKaVUPTHGtHYajomIZAN7j/P2eCCnGZPT2jpSfjQvbZPmpW06nrz0MsYkHO2idhcUToSIrDDGjGrtdDSXjpQfzUvbpHlpm7yZF20+UkopVU+DglJKqXq+FhReaO0ENLOOlB/NS9ukeWmbvJYXn+pTUEopdWS+VlNQSil1BBoUlFJK1fOZoCAik0Rkq4jsEJGHWjs9x0JEeojIVyKyWUQ2isjdzvFYEVkkItudv2NaO62eEhF/EVktIp84n9tlXkQkWkTeFZEtzn+fse04L/c6/742iMjbIhLSnvIiIrNFJEtENrgdazL9IvKwUx5sFZELWifVjWsiL487/87Wich/RSTa7Vyz5cUngoKI+APPAJOBwcCVIjK4dVN1TGqAXxtjBgGnAXc46X8I+MIY0w/4wvncXtwNbHb73F7z8hSwwBgzEBiOzVO7y4uIdAPuAkYZY4YC/sAM2ldeXgEmNTjWaPqd/39mAEOce551yom24hUOz8siYKgxZhiwDXgYmj8vPhEUgNHADmPMLmNMFTAHmNbKafKYMWa/MWaV83MxtuDphs3Dq85lrwKXtE4Kj42IdAcuAl5yO9zu8iIinYDxwH8AjDFVxpgC2mFeHAFAqIgEAGFABu0oL8aYr4G8BoebSv80YI4xptIYsxvYgS0n2oTG8mKMWWiMqXE+/gB0d35u1rz4SlDoBqS6fU5zjrU7IpIMnAz8CHQ2xuwHGziAxNZL2TF5EvgN4HI71h7z0hvIBl52msJeEpFw2mFejDHpwN+BfcB+oNAYs5B2mJcGmkp/ey8TbgI+c35u1rz4SlCQRo61u7G4IhIBvAfcY4wpau30HA8RmQJkGWNWtnZamkEAcArwnDHmZKCUtt280iSnrX0akAIkAeEick3rpsqr2m2ZICK/wzYpv1l3qJHLjjsvvhIU0oAebp+7Y6vG7YaIBGIDwpvGmPedw5ki0tU53xXIaq30HYMzgKkisgfbjHeOiLxB+8xLGpBmjPnR+fwuNki0x7ycB+w2xmQbY6qB94HTaZ95cddU+ttlmSAi1wNTgKvNwUlmzZoXXwkKy4F+IpIiIkHYTpmPWjlNHhMRwbZbbzbG/MPt1EfA9c7P1wMftnTajpUx5mFjTHdjTDL2v8OXxphraJ95OQCkisgA59C5wCbaYV6wzUaniUiY8+/tXGzfVXvMi7um0v8RMENEgkUkBegH/NQK6fOYiEwCHgSmGmPK3E41b16MMT7xB7gQ22O/E/hda6fnGNN+JrY6uA5Y4/y5EIjDjqjY7vwd29ppPcZ8TQA+cX5ul3kBRgArnP82HwAx7TgvjwJbgA3A60Bwe8oL8Da2P6Qa+/Z885HSD/zOKQ+2ApNbO/0e5GUHtu+grgyY5Y286DIXSiml6vlK85FSSikPaFBQSilVT4OCUkqpehoUlFJK1dOgoJRSqp4GBaVakIhMqFsZVqm2SIOCUkqpehoUlGqEiFwjIj+JyBoRed7Z/6FERJ4QkVUi8oWIJDjXjhCRH9zWuY9xjvcVkcUista5p4/z+Ai3PRjedGYQK9UmaFBQqgERGQRcAZxhjBkB1AJXA+HAKmPMKcBS4I/OLa8BDxq7zv16t+NvAs8YY4Zj1xHa7xw/GbgHu7dHb+x6UEq1CQGtnQCl2qBzgZHAcuclPhS7kJoLmOtc8wbwvohEAdHGmKXO8VeBd0QkEuhmjPkvgDGmAsB53k/GmDTn8xogGfjW+9lS6ug0KCh1OAFeNcY8fMhBkUcaXHekNWKO1CRU6fZzLfr/oWpDtPlIqcN9AVwmIolQv89vL+z/L5c511wFfGuMKQTyRWScc/xaYKmx+12kicglzjOCRSSsRXOh1HHQNxSlGjDGbBKR3wMLRcQPu1LlHdhNdIaIyEqgENvvAHZJ5llOob8LuNE5fi3wvIj8j/OMy1swG0odF10lVSkPiUiJMSaitdOhlDdp85FSSql6WlNQSilVT2sKSiml6mlQUEopVU+DglJKqXoaFJRSStXToKCUUqre/wdgjnFYHnIsiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy\n",
    "- Train Accuracy: 0.94\n",
    "- Test Accuracy:  0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999994\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9903572\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks a lot ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
